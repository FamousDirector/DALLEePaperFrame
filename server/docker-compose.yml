version: '3'

services:
  triton-inference-server:
    container_name: triton-inference-server
    image: triton-inference-server
    command:
      - /opt/tritonserver/bin/tritonserver
      - --model-store=/model_repo
      - --allow-metrics=true
      - --model-control-mode=poll
    volumes:
      - ./model_repo:/model_repo
    shm_size: "2g"

  art-generator-api:
    container_name: art-generator-api
    image: art-generator-api
    command: "uvicorn server_api:app --reload --port 8000 --host 0.0.0.0"
    volumes:
      - ./api:/workspace
    ports:
      - "8000:8000"
    depends_on:
      - triton-inference-server